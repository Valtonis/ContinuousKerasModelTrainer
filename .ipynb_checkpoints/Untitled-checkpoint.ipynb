{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from random import shuffle\n",
    "\n",
    "def GeneratorInfinite(rowNumbers, batch_size, preparedData):\n",
    "    modulo = len(rowNumbers) % batch_size\n",
    "    numberOfDataPieces = None\n",
    "    if modulo != 0:\n",
    "        numberOfDataPieces = math.ceil(len(rowNumbers) / batch_size)\n",
    "    else:\n",
    "        numberOfDataPieces = math.floor(len(rowNumbers) / batch_size)\n",
    "    idx = 0\n",
    "    while True:\n",
    "        X_res = None\n",
    "        y_res = None\n",
    "        beginIndexInSequence = idx * batch_size\n",
    "        sequenceLength = None\n",
    "        if idx < numberOfDataPieces - 1:\n",
    "            sequenceLength = batch_size\n",
    "        else:\n",
    "            sequenceLength = len(rowNumbers) - beginIndexInSequence\n",
    "        X_res = preparedData[0][rowNumbers[beginIndexInSequence : beginIndexInSequence + sequenceLength]]\n",
    "        '''X_res = pad_sequences(records[0], \n",
    "                             necessaryNumberOfWordsInDocument, \n",
    "                             truncating='post')'''\n",
    "        #X_res = padSequence(records[0], necessaryNumberOfWordsInDocument)\n",
    "        y_res = preparedData[1][rowNumbers[beginIndexInSequence : beginIndexInSequence + sequenceLength]]\n",
    "        yield (X_res, y_res)\n",
    "        idx += 1\n",
    "        if idx == numberOfDataPieces:\n",
    "            idx = 0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def refillTemporaryStorage(dataPuller, temporaryStorage, temporaryStorageSize):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GeneratorInfinite(indexes, dataPuller, batchSize, temporaryStorageSize=1):\n",
    "    indexes = copy.deepcopy(indexes)\n",
    "    modulo = len(rowNumbers) % batch_size\n",
    "    numberOfDataPieces = None\n",
    "    if modulo != 0:\n",
    "        numberOfDataPieces = math.ceil(len(rowNumbers) / batch_size)\n",
    "    else:\n",
    "        numberOfDataPieces = math.floor(len(rowNumbers) / batch_size)\n",
    "    idx = 0\n",
    "    while True:\n",
    "        X_res = None\n",
    "        y_res = None\n",
    "        beginIndexInSequence = idx * batch_size\n",
    "        sequenceLength = None\n",
    "        if idx < numberOfDataPieces - 1:\n",
    "            sequenceLength = batch_size\n",
    "        else:\n",
    "            sequenceLength = len(rowNumbers) - beginIndexInSequence\n",
    "        X_res = preparedData[0][rowNumbers[beginIndexInSequence : beginIndexInSequence + sequenceLength]]\n",
    "        y_res = preparedData[1][rowNumbers[beginIndexInSequence : beginIndexInSequence + sequenceLength]]\n",
    "        yield (X_res, y_res)\n",
    "        idx += 1\n",
    "        if idx == numberOfDataPieces:\n",
    "            idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GeneratorFinite(Sequence):\n",
    "    def __init__(self, rowNumbers, batchSize, preparedData):\n",
    "        self.__rowNumbers = rowNumbers\n",
    "        self.__batchSize = batchSize\n",
    "        self.__preparedData = preparedData\n",
    "        \n",
    "        modulo = len(self.__rowNumbers) % self.__batchSize\n",
    "        if modulo != 0:\n",
    "            self.__len = math.ceil(len(self.__rowNumbers) / self.__batchSize)\n",
    "        else:\n",
    "            self.__len = math.floor(len(self.__rowNumbers) / self.__batchSize)\n",
    "    def __len__(self):\n",
    "        return self.__len\n",
    "    def __getitem__(self, idx):\n",
    "        beginIndexInSequence = idx * self.__batchSize\n",
    "        sequenceLength = None\n",
    "        if idx < self.__len__() - 1:\n",
    "            sequenceLength = self.__batchSize\n",
    "        else:\n",
    "            sequenceLength = len(self.__rowNumbers) - beginIndexInSequence\n",
    "        X_res = self.__preparedData[0][self.__rowNumbers[beginIndexInSequence : beginIndexInSequence + sequenceLength]]\n",
    "        '''X_res = pad_sequences(records[0], \n",
    "                             self.__necessaryNumberOfWordsInDocument, \n",
    "                             truncating='post')'''\n",
    "        #X_res = padSequence(records[0], self.__necessaryNumberOfWordsInDocument)\n",
    "        y_res = self.__preparedData[1][self.__rowNumbers[beginIndexInSequence : beginIndexInSequence + sequenceLength]]\n",
    "        return (X_res, y_res)\n",
    "    __rowNumbers = None\n",
    "    __batchSize = None\n",
    "    __preparedData = None\n",
    "    __len = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GeneratorForKerasNetwork(Sequence):\n",
    "    def __init__(self, indexes, dataPuller, batchSize, temporaryStorageSize=1):\n",
    "        self.__dataPuller = dataPuller\n",
    "        self.__indexes = indexes\n",
    "        if batchSize > len(indexes):\n",
    "            batchSize = len(indexes)\n",
    "        self.__batchSize = batchSize\n",
    "        \n",
    "        modulo = len(self.__indexes) % self.__batchSize\n",
    "        if modulo != 0:\n",
    "            self.__len = math.ceil(len(self.__indexes) / self.__batchSize)\n",
    "        else:\n",
    "            self.__len = math.floor(len(self.__indexes) / self.__batchSize)\n",
    "        if temporaryStorageSize > self.__len:\n",
    "            temporaryStorageSize = self.__len\n",
    "        self.__temporaryStorageSize = temporaryStorageSize\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.__len\n",
    "    \n",
    "    def __next__(self):\n",
    "        \n",
    "        def getLocalIndexCounter(maxIndex):\n",
    "            if getLocalIndexCounter.hasattr(\"idx\"):\n",
    "                getLocalIndexCounter.idx += 1\n",
    "                getLocalIndexCounter.idx = getLocalIndexCounter.idx % maxIndex\n",
    "            else:\n",
    "                getLocalIndexCounter.idx = 0\n",
    "            return getLocalIndexCounter.idx\n",
    "        \n",
    "        idx = getLocalIndexCounter(self.__len__())\n",
    "        data = self.__getitem__(idx)\n",
    "        return data\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.__loadedBatches is None or idx not in self.__loadedBatches:\n",
    "            self.__firstLoadedBatchIndex = idx\n",
    "            batchesToLoad = []\n",
    "            for shift in range(self.__temporaryStorageSize):\n",
    "                batchesToLoad.append((idx + shift) % self.__len)\n",
    "            self._loadRecordsInTemporaryStorage(batchesToLoad)\n",
    "        return self._getPreloadedBatch(idx - self.__firstLoadedBatchIndex)\n",
    "    \n",
    "    def _calculateBatchRecordsDistribution(self):\n",
    "        self.__batchRecordIndexes = [None] * __len\n",
    "        idx = 0\n",
    "        while idx < __len:\n",
    "            beginIndexInSequence = idx * self.__batchSize\n",
    "            if idx < self.__len__() - 1:\n",
    "                self.__batchRecordIndexes[idx] = self.__indexes[beginIndexInSequence : beginIndexInSequence + self.__batchSize]\n",
    "            else:\n",
    "                self.__batchRecordIndexes[idx] = self.__indexes[beginIndexInSequence : len(self.__indexes)]\n",
    "            idx += 1\n",
    "        \n",
    "    def _loadRecordsInTemporaryStorage(self, batchIndexes):\n",
    "        recordIndexes = []\n",
    "        for batchNum in batchIndexes:\n",
    "            recordIndexes += self.__batchRecordIndexes[batchNum]\n",
    "        self.__loadedBatches = batchIndexes\n",
    "        batchesData = self.__dataPuller.getData(recordIndexes)\n",
    "        z = list(zip(batchesData[0], batchesData[1]))\n",
    "        shuffle(z)\n",
    "        self.__temporaryStorage = zip(*z)\n",
    "        \n",
    "    def _getPreloadedBatch(self, num):\n",
    "        beginIndexInSequence = num * self.__batchSize\n",
    "        X = None\n",
    "        y = None\n",
    "        if idx < len(self.__loadedBatches) - 1:\n",
    "            X = self.__temporaryStorage[0][beginIndexInSequence : beginIndexInSequence + self.__batchSize]\n",
    "            y = self.__temporaryStorage[1][beginIndexInSequence : beginIndexInSequence + self.__batchSize]\n",
    "        else:\n",
    "            X = self.__temporaryStorage[0][beginIndexInSequence : len(self.__temporaryStorage[0])]\n",
    "            y = self.__temporaryStorage[1][beginIndexInSequence : len(self.__temporaryStorage[0])]\n",
    "        return (X, y)\n",
    "    \n",
    "    # Fields:\n",
    "    \n",
    "    __dataPuller = None\n",
    "    __indexes = None\n",
    "    __batchSize = None\n",
    "    __len = None\n",
    "    \n",
    "    __batchRecordIndexes = None\n",
    "    __temporaryStorage = None\n",
    "    __temporaryStorageSize = None\n",
    "    __loadedBatches = None\n",
    "                                               \n",
    "    __firstLoadedBatchIndex = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
